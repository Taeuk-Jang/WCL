{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }<\\style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }<\\style>\"))\n",
    "\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1,2,3'\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "from torch.nn.functional import one_hot as one_hot\n",
    "import torch.utils.data as data\n",
    "import utils\n",
    "from model import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dataset_name = 'tiny-imagenet'\n",
    "\n",
    "lr = 1e-3\n",
    "device = 'cuda:0'\n",
    "tau_plus = 0.01\n",
    "\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, memory_data, test_data = utils.get_dataset(dataset_name, root='../data')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=12, pin_memory=True, drop_last=True)\n",
    "memory_loader = DataLoader(memory_data, batch_size=batch_size, shuffle=False, num_workers=12, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=12, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_plus =0.1\n",
    "beta =1\n",
    "estimator = 'hard'\n",
    "temperature =0.5\n",
    "epoch = 20\n",
    "epochs = 400\n",
    "k = 200\n",
    "c = len(train_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negative_mask(batch_size):\n",
    "    negative_mask = torch.ones((batch_size, 2 * batch_size), dtype=bool)\n",
    "    for i in range(batch_size):\n",
    "        negative_mask[i, i] = 0\n",
    "        negative_mask[i, i + batch_size] = 0\n",
    "\n",
    "    negative_mask = torch.cat((negative_mask, negative_mask), 0)\n",
    "    return negative_mask\n",
    "\n",
    "def triplet(out_1,out_2,tau_plus,batch_size,temperature, debias = True):\n",
    "    N = batch_size * 2 - 2\n",
    "    out = torch.cat([out_1, out_2], dim=0) # 2 * bs x fs\n",
    "    s = torch.pow(out.unsqueeze(0) - out.unsqueeze(1), 2).sum(-1) # 2 * bs x 2 * bs\n",
    "    mask = get_negative_mask(batch_size).to(device)\n",
    "    \n",
    "    if debias:\n",
    "        s = s.masked_select(mask).view(2 * batch_size, -1)  # (2 * bs, 2 * bs - 2) : subtract self and its augment\n",
    "\n",
    "        pos = (torch.pow(out_1 - out_2, 2))\n",
    "        pos = torch.cat([pos, pos], dim=0).sum(-1)\n",
    "\n",
    "        neg = (-tau_plus * N * pos + s.sum(-1)) / (1 - tau_plus)\n",
    "\n",
    "    else:\n",
    "        neg = s.masked_select(mask).view(2 * batch_size, -1)  # (2 * bs, 2 * bs - 2) : subtract self and its augment\n",
    "\n",
    "        pos = (torch.pow(out_1 - out_2, 2))\n",
    "        pos = torch.cat([pos, pos], dim=0).sum(-1)\n",
    "\n",
    "    return (pos - neg).mean()\n",
    "\n",
    "def W(out_d, out_b, batch_size):\n",
    "    mask = get_negative_mask(batch_size).to(device)\n",
    "    \n",
    "    # difficulty by distance\n",
    "#     s_d =  torch.pow(out_d.unsqueeze(0) - out_d.unsqueeze(1), 2).sum(-1)\n",
    "#     s_d = s_d.masked_select(mask).view(2 * batch_size, -1) / temperature\n",
    "#     s_b =  torch.pow(out_b.unsqueeze(0) - out_b.unsqueeze(1), 2).sum(-1)\n",
    "#     s_b = s_b.masked_select(mask).view(2 * batch_size, -1) / temperature\n",
    "    \n",
    "#     difficulty by cosine similarity\n",
    "    s_d = torch.exp(torch.mm(out_d, out_d.t().contiguous()) / temperature)\n",
    "    s_d = s_d.masked_select(mask).view(2 * batch_size, -1) # (2 * bs, 2 * bs - 2) : subtract self and its augment\n",
    "    s_d = F.normalize(s_d, dim = -1)\n",
    "    \n",
    "    s_b = torch.exp(torch.mm(out_b, out_b.t().contiguous()) / temperature)\n",
    "    s_b = s_b.masked_select(mask).view(2 * batch_size, -1) # (2 * bs, 2 * bs - 2) : subtract self and its augment\n",
    "    s_b = F.normalize(s_b, dim = -1)\n",
    "    \n",
    "    weight = 1 + s_d / (s_b + s_d + 1e-6)\n",
    "#     print(weight)\n",
    "    if np.isnan(weight.sum().item()):\n",
    "        print('weight NaN')\n",
    "        \n",
    "    return weight.detach()\n",
    "    \n",
    "def orientation(out_1_d,out_2_d,out_1_b,out_2_b,batch_size):\n",
    "    #space sharing\n",
    "    out_d = torch.cat([out_1_d,out_2_d], dim=0)\n",
    "    out_b = torch.cat([out_1_b,out_2_b], dim=0)\n",
    "#     print(out_d)\n",
    "#     print(out_b)\n",
    "#     print(nn.MSELoss(reduction = 'sum')(out_d, out_b)/batch_size)\n",
    "#     return nn.MSELoss(reduction = 'sum')(out_d, out_b)/batch_size\n",
    "#    return (torch.pow(out_d - out_b, 2) / temperature).mean()\n",
    "    return -torch.log(torch.exp((out_d * out_b).sum(-1)/temperature)).mean() \n",
    "    \n",
    "def criterion(out_1_d, out_2_d, out_1_b, out_2_b, tau_plus, batch_size, beta, temperature):\n",
    "    # neg score\n",
    "    out = torch.cat([out_1_d, out_2_d], dim=0)\n",
    "    out_b = torch.cat([out_1_b, out_2_b], dim=0)\n",
    "    neg = torch.exp(torch.mm(out, out.t().contiguous()) / temperature)\n",
    "    mask = get_negative_mask(batch_size).to(device)\n",
    "    neg = neg.masked_select(mask).view(2 * batch_size, -1) # (2 * bs, bs - 2) : subtract self and its augment\n",
    "\n",
    "    # pos score\n",
    "    pos = torch.exp(torch.sum(out_1_d * out_2_d, dim=-1) / temperature)\n",
    "    pos = torch.cat([pos, pos], dim=0)\n",
    "    \n",
    "    weight = W(out, out_b, batch_size) # (2 * bs, bs - 2)\n",
    "\n",
    "    # negative samples similarity scoring\n",
    "    N = batch_size * 2 - 2\n",
    "#         imp = (beta* neg.log()).exp()\n",
    "#         reweight_neg = (imp*neg).sum(dim = -1) / imp.mean(dim = -1)\n",
    "    reweight_neg = weight * neg\n",
    "\n",
    "    Ng = (-tau_plus * N * pos + reweight_neg.sum(dim = -1)) / (1 - tau_plus)\n",
    "    # constrain (optional)\n",
    "    Ng = torch.clamp(Ng, min = N * np.e**(-1 / temperature))\n",
    "\n",
    "    # contrastive loss\n",
    "    loss = (-torch.log(pos / (pos + Ng) )).mean()\n",
    "    \n",
    "    if np.isnan(loss.mean().item()):\n",
    "#         print(\"pos : \", pos)\n",
    "#         print(\"Ng : \", Ng)\n",
    "        print(\"neg : \", neg)\n",
    "    \n",
    "        np.savetxt('pos.txt', pos.detach().cpu().numpy(), delimiter=',')\n",
    "        np.savetxt('Ng.txt', Ng.detach().cpu().numpy(), delimiter=',')\n",
    "        np.savetxt('neg.txt', neg.detach().cpu().numpy(), delimiter=',')\n",
    "        np.savetxt('weight.txt', weight.detach().cpu().numpy(), delimiter=',')\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d = Image_Model()\n",
    "model_d = nn.DataParallel(model_d).cuda()\n",
    "\n",
    "\n",
    "model_b = Image_Model()\n",
    "model_b = nn.DataParallel(model_b).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'tiny-im/results/{}_v2/{}'.format('wctr', 'tiny-imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tiny-im/results/wctr_v2/tiny-imagenet/model_d_512_0.1_50.pth'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(save_dir, 'model_d_512_0.1_50.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../results/imagenet/wcl/no_orient_new/imagenet_model_b_256_0.01_0.07_0.03_0.005_500.pth'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = '../results/imagenet/wcl/no_orient_new'\n",
    "os.path.join(save_dir, 'imagenet_model_b_256_0.01_0.07_0.03_0.005_500.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_d.load_state_dict(torch.load(os.path.join(save_dir, 'imagenet_model_d_256_0.01_0.07_0.03_0.005_500.pth'.format(batch_size,tau_plus,epoch))))\n",
    "model_b.load_state_dict(torch.load(os.path.join(save_dir, 'imagenet_model_b_256_0.01_0.07_0.03_0.005_500.pth'.format(batch_size,tau_plus,epoch))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_1, pos_2, target = iter(train_loader).next()\n",
    "pos_1, pos_2 = pos_1.cuda(), pos_2.cuda()\n",
    "\n",
    "feature_1, out_1_d = model_d(pos_1)\n",
    "feature_2, out_2_d = model_d(pos_2)\n",
    "\n",
    "feature_1, out_1_b = model_b(pos_1)\n",
    "feature_2, out_2_b = model_b(pos_2)\n",
    "\n",
    "#         loss_tri = triplet(out_1_b, out_2_b, batch_size)\n",
    "loss_tri = triplet(out_1_b, out_2_b, tau_plus, batch_size, temperature, True)\n",
    "#         loss_ori = orientation(out_1_d, out_2_d, out_1_b, out_2_b, batch_size)\n",
    "loss_crt = criterion(out_1_d, out_2_d, out_1_b, out_2_b, tau_plus, batch_size, beta, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_d = torch.cat([out_1_d, out_1_d], dim = 0)\n",
    "out_b = torch.cat([out_1_b, out_1_b], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = get_negative_mask(batch_size).to(device)\n",
    "\n",
    "# difficulty by distance\n",
    "#     s_d =  torch.pow(out_d.unsqueeze(0) - out_d.unsqueeze(1), 2).sum(-1)\n",
    "#     s_d = s_d.masked_select(mask).view(2 * batch_size, -1) / temperature\n",
    "#     s_b =  torch.pow(out_b.unsqueeze(0) - out_b.unsqueeze(1), 2).sum(-1)\n",
    "#     s_b = s_b.masked_select(mask).view(2 * batch_size, -1) / temperature\n",
    "\n",
    "#     difficulty by cosine similarity\n",
    "s_d = torch.exp(torch.mm(out_d, out_d.t().contiguous()) / temperature)\n",
    "s_d = s_d.masked_select(mask).view(2 * batch_size, -1) # (2 * bs, 2 * bs - 2) : subtract self and its augment\n",
    "s_d = F.normalize(s_d, dim = -1)\n",
    "\n",
    "s_b = torch.exp(torch.mm(out_b, out_b.t().contiguous()) / temperature)\n",
    "s_b = s_b.masked_select(mask).view(2 * batch_size, -1) # (2 * bs, 2 * bs - 2) : subtract self and its augment\n",
    "s_b = F.normalize(s_b, dim = -1)\n",
    "\n",
    "weight = 1 + s_d / (s_b + s_d + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.cat([out_1_d, out_2_d], dim=0)\n",
    "neg = torch.exp(torch.mm(out, out.t().contiguous()) / temperature)\n",
    "# mask = get_negative_mask(batch_size).to(device)\n",
    "# neg = neg.masked_select(mask).view(2 * batch_size, -1) # (2 * bs, bs - 2) : subtract self and its augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = torch.exp(torch.sum(out_1_d * out_2_d, dim=-1) / temperature)\n",
    "pos = torch.cat([pos, pos], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.1965, 6.4684, 6.6369, 5.1381, 7.2278, 6.5985, 5.7907, 7.2830, 7.2033,\n",
       "        5.3678, 7.3236, 6.3417, 7.2716, 7.3307, 5.4713, 6.4377, 6.6081, 5.1806,\n",
       "        5.3092, 7.1126, 6.7840, 6.6477, 7.3575, 6.4398, 7.3449, 6.0548, 4.6535,\n",
       "        6.4515, 6.1537, 6.0765, 7.3122, 6.2015, 5.8231, 5.9929, 7.3526, 7.3533,\n",
       "        7.3270, 5.9478, 7.2632, 7.3291, 7.2754, 6.6456, 7.2601, 6.8021, 7.3570,\n",
       "        5.1825, 6.6082, 7.3115, 7.3356, 5.6945, 7.2748, 7.3138, 7.3522, 7.3571,\n",
       "        7.3456, 7.3515, 5.8596, 6.7059, 5.6224, 7.2870, 7.2970, 7.3388, 7.3248,\n",
       "        6.1510, 6.1965, 6.4684, 6.6369, 5.1381, 7.2278, 6.5985, 5.7907, 7.2830,\n",
       "        7.2033, 5.3678, 7.3236, 6.3417, 7.2716, 7.3307, 5.4713, 6.4377, 6.6081,\n",
       "        5.1806, 5.3092, 7.1126, 6.7840, 6.6477, 7.3575, 6.4398, 7.3449, 6.0548,\n",
       "        4.6535, 6.4515, 6.1537, 6.0765, 7.3122, 6.2015, 5.8231, 5.9929, 7.3526,\n",
       "        7.3533, 7.3270, 5.9478, 7.2632, 7.3291, 7.2754, 6.6456, 7.2601, 6.8021,\n",
       "        7.3570, 5.1825, 6.6082, 7.3115, 7.3356, 5.6945, 7.2748, 7.3138, 7.3522,\n",
       "        7.3571, 7.3456, 7.3515, 5.8596, 6.7059, 5.6224, 7.2870, 7.2970, 7.3388,\n",
       "        7.3248, 6.1510], device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = batch_size * 2 - 2\n",
    "out = torch.cat([out_1_b, out_2_b], dim=0) # 2 * bs x fs\n",
    "s = torch.pow(out.unsqueeze(0) - out.unsqueeze(1), 2).sum(-1) # 2 * bs x 2 * bs\n",
    "mask = get_negative_mask(batch_size).to(device)\n",
    "\n",
    "s = s.masked_select(mask).view(2 * batch_size, -1)  # (2 * bs, 2 * bs - 2) : subtract self and its augment\n",
    "\n",
    "pos = (torch.pow(out_1_b - out_2_b, 2))\n",
    "pos = torch.cat([pos, pos], dim=0).sum(-1)\n",
    "\n",
    "neg = (-tau_plus * N * pos + s.sum(-1)) / (1 - tau_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.1938, -2.2426, -2.2314, -2.2796, -2.2426, -2.3109, -2.2128, -2.2007,\n",
       "        -2.2298, -2.2087, -2.2826, -2.2054, -2.2269, -2.3162, -2.1834, -2.1977,\n",
       "        -2.1322, -2.3097, -2.2710, -2.3155, -2.2893, -2.2327, -2.2134, -2.3082,\n",
       "        -2.3050, -2.3109, -2.2172, -2.2030, -2.2078, -2.2281, -2.2679, -2.2002,\n",
       "        -2.3042, -2.1847, -2.3172, -2.2421, -2.1983, -2.2168, -2.2100, -2.2937,\n",
       "        -2.3048, -2.2206, -2.3112, -2.1504, -2.2203, -2.1878, -2.2833, -2.2676,\n",
       "        -2.1439, -2.1972, -2.2368, -2.3055, -2.2941, -2.3074, -2.2097, -2.2594,\n",
       "        -2.2567, -2.2960, -2.2355, -2.1983, -2.2047, -2.2086, -2.2510, -2.3137,\n",
       "        -2.2338, -2.2189, -2.2166, -2.2622, -2.2386, -2.3107, -2.2411, -2.1958,\n",
       "        -2.2267, -2.2138, -2.2937, -2.1858, -2.2298, -2.3155, -2.1854, -2.1977,\n",
       "        -2.1837, -2.3125, -2.2577, -2.3157, -2.2897, -2.2372, -2.2127, -2.3038,\n",
       "        -2.3044, -2.3075, -2.1980, -2.1957, -2.1871, -2.2358, -2.2675, -2.2062,\n",
       "        -2.3090, -2.1858, -2.3172, -2.2408, -2.1978, -2.2073, -2.2208, -2.2887,\n",
       "        -2.3031, -2.2008, -2.3089, -2.2019, -2.2127, -2.1945, -2.2862, -2.2671,\n",
       "        -2.0782, -2.1832, -2.2321, -2.3030, -2.3010, -2.3083, -2.2086, -2.2525,\n",
       "        -2.2782, -2.3040, -2.2251, -2.2022, -2.2072, -2.2101, -2.2536, -2.3128],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tau_plus * pos - s.mean(-1))/(1-tau_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0332, 3.8393, 0.5072,  ..., 3.0464, 3.9708, 1.4636],\n",
       "        [0.0332, 3.9513, 0.2904,  ..., 3.3384, 3.9999, 1.1228],\n",
       "        [3.8393, 3.9513, 3.8956,  ..., 0.3683, 0.0539, 3.2500],\n",
       "        ...,\n",
       "        [3.0464, 3.3384, 0.3683,  ..., 0.0042, 0.6789, 3.9226],\n",
       "        [3.9708, 3.9999, 0.0539,  ..., 0.7792, 0.6789, 2.8563],\n",
       "        [1.4636, 1.1228, 3.2500,  ..., 3.9543, 3.9226, 2.8563]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:main]",
   "language": "python",
   "name": "conda-env-main-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
