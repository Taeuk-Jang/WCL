{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6dea6068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchvision.models as models\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "470f9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7637d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/imagenet/LOC_val_solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "250c6362",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = pd.read_csv('/data/imagenet/LOC_val_solution.csv').PredictionString.apply(lambda x: x.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4da2b089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ILSVRC2012_val_00048981</td>\n",
       "      <td>n03995372 85 1 499 272</td>\n",
       "      <td>n03995372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ILSVRC2012_val_00037956</td>\n",
       "      <td>n03481172 131 0 499 254</td>\n",
       "      <td>n03481172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ILSVRC2012_val_00026161</td>\n",
       "      <td>n02108000 38 0 464 280</td>\n",
       "      <td>n02108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ILSVRC2012_val_00026171</td>\n",
       "      <td>n03109150 0 14 216 299</td>\n",
       "      <td>n03109150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ILSVRC2012_val_00008726</td>\n",
       "      <td>n02119789 255 142 454 329 n02119789 44 21 322 ...</td>\n",
       "      <td>n02119789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>ILSVRC2012_val_00005961</td>\n",
       "      <td>n03388043 103 0 279 472</td>\n",
       "      <td>n03388043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>ILSVRC2012_val_00008801</td>\n",
       "      <td>n03089624 101 286 170 374 n03089624 236 282 30...</td>\n",
       "      <td>n03089624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>ILSVRC2012_val_00008176</td>\n",
       "      <td>n01518878 82 98 439 498</td>\n",
       "      <td>n01518878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>ILSVRC2012_val_00004764</td>\n",
       "      <td>n03874293 91 111 490 420</td>\n",
       "      <td>n03874293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>ILSVRC2012_val_00031847</td>\n",
       "      <td>n01855032 48 92 415 227</td>\n",
       "      <td>n01855032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ImageId  \\\n",
       "0      ILSVRC2012_val_00048981   \n",
       "1      ILSVRC2012_val_00037956   \n",
       "2      ILSVRC2012_val_00026161   \n",
       "3      ILSVRC2012_val_00026171   \n",
       "4      ILSVRC2012_val_00008726   \n",
       "...                        ...   \n",
       "49995  ILSVRC2012_val_00005961   \n",
       "49996  ILSVRC2012_val_00008801   \n",
       "49997  ILSVRC2012_val_00008176   \n",
       "49998  ILSVRC2012_val_00004764   \n",
       "49999  ILSVRC2012_val_00031847   \n",
       "\n",
       "                                        PredictionString      class  \n",
       "0                                n03995372 85 1 499 272   n03995372  \n",
       "1                               n03481172 131 0 499 254   n03481172  \n",
       "2                                n02108000 38 0 464 280   n02108000  \n",
       "3                                n03109150 0 14 216 299   n03109150  \n",
       "4      n02119789 255 142 454 329 n02119789 44 21 322 ...  n02119789  \n",
       "...                                                  ...        ...  \n",
       "49995                           n03388043 103 0 279 472   n03388043  \n",
       "49996  n03089624 101 286 170 374 n03089624 236 282 30...  n03089624  \n",
       "49997                           n01518878 82 98 439 498   n01518878  \n",
       "49998                          n03874293 91 111 490 420   n03874293  \n",
       "49999                           n01855032 48 92 415 227   n01855032  \n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2e217b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/imagenet/ILSVRC/Data/CLS-LOC/val/'\n",
    "\n",
    "for i in range(len(df)):\n",
    "    label = df['class'][i]\n",
    "    \n",
    "    if not os.path.exists(os.path.join(data_dir, label)):\n",
    "        os.makedirs(os.path.join(data_dir, label))\n",
    "        \n",
    "    else:\n",
    "        shutil.move(os.path.join(data_dir, df['ImageId'][i])+\".JPEG\", os.path.join(data_dir, label, df['ImageId'][i])+\".JPEG\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "352914a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/data/imagenet-100/train'\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = ImageFolder(\n",
    "        train_dir,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "80a4cc9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3652,  0.3481,  0.3652,  ..., -0.1999, -0.3369, -0.4739],\n",
       "          [ 0.3652,  0.3652,  0.3652,  ..., -0.1657, -0.2856, -0.3712],\n",
       "          [ 0.3652,  0.3823,  0.3652,  ..., -0.2342, -0.3541, -0.3883],\n",
       "          ...,\n",
       "          [ 2.2147,  2.2489,  2.2489,  ..., -0.5424, -0.5938, -0.6109],\n",
       "          [ 2.2318,  2.2489,  2.2489,  ..., -0.5767, -0.6452, -0.6965],\n",
       "          [ 2.2147,  2.2318,  2.2318,  ..., -0.6281, -0.7308, -0.7479]],\n",
       " \n",
       "         [[ 0.2052,  0.1877,  0.2052,  ..., -0.6702, -0.8102, -0.8978],\n",
       "          [ 0.2052,  0.2227,  0.2227,  ..., -0.5301, -0.6702, -0.7752],\n",
       "          [ 0.2052,  0.2227,  0.2402,  ..., -0.4776, -0.6176, -0.7227],\n",
       "          ...,\n",
       "          [ 2.4111,  2.4111,  2.4111,  ..., -0.8803, -0.8452, -0.8102],\n",
       "          [ 2.4286,  2.4111,  2.4111,  ..., -0.9153, -0.8978, -0.9328],\n",
       "          [ 2.4286,  2.4286,  2.4111,  ..., -0.9503, -0.9503, -0.9853]],\n",
       " \n",
       "         [[ 0.1302,  0.1476,  0.1476,  ..., -0.6715, -0.8110, -0.9156],\n",
       "          [ 0.1302,  0.1476,  0.1651,  ..., -0.4798, -0.6541, -0.7238],\n",
       "          [ 0.1476,  0.1651,  0.1651,  ..., -0.4101, -0.5321, -0.5844],\n",
       "          ...,\n",
       "          [ 2.5703,  2.5877,  2.6226,  ..., -0.6018, -0.6193, -0.6018],\n",
       "          [ 2.5877,  2.5877,  2.6226,  ..., -0.7238, -0.7238, -0.7238],\n",
       "          [ 2.5703,  2.6051,  2.5877,  ..., -0.7761, -0.7936, -0.7936]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0cc8d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = ImageFolderInstance(train_dir, transform=transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]), two_crop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e4b54c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 224, 224])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "516c63db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderInstance(datasets.ImageFolder):\n",
    "    \"\"\"Folder datasets which returns the index of the image as well\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, transform=None, target_transform=None, two_crop=False):\n",
    "        super(ImageFolderInstance, self).__init__(root, transform, target_transform)\n",
    "        self.two_crop = two_crop\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target, index) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        path, target = self.imgs[index]\n",
    "        image = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        if self.two_crop:\n",
    "            img2 = self.transform(image)\n",
    "            img = torch.cat([img, img2], dim=0)\n",
    "\n",
    "        return img, target, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e4724d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126689"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a0551fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dir = '/data/imagenet-100/val'\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "val_dataset = ImageFolder(\n",
    "        val_dir,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f488955b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4906"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a0f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "--source_folder: specify the ImageNet-1K data folder (e.g., /root/data/imagenet/train)\n",
    "--target_folder: specify the ImageNet-100 data folder (e.g., /root/data/imagenet-100/train)\n",
    "--target_class: specify the ImageNet-100 txt file with list of classes [default: 'IN100.txt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cd967d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = '/data/imagenet/ILSVRC/Data/CLS-LOC/val/'\n",
    "target_folder = '/data/imagenet-100/val'\n",
    "target_class = 'imagenet100.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d42d6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c12af08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(source_folder, target_folder, target_class):\n",
    "\n",
    "    txt_data = open(target_class, \"r\") \n",
    "    for ids, txt in enumerate(txt_data):\n",
    "        s = str(txt.split('\\n')[0])\n",
    "        f.append(s)\n",
    "\n",
    "    for ids, dirs in enumerate(os.listdir(source_folder)):\n",
    "        for tg_class in f:\n",
    "            if dirs == tg_class:\n",
    "                print('{} is transferred'.format(dirs))\n",
    "                shutil.copytree(os.path.join(source_folder,dirs), os.path.join(target_folder,dirs)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "887144f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n01980166 is transferred\n",
      "n01735189 is transferred\n",
      "n02259212 is transferred\n",
      "n02018207 is transferred\n",
      "n02107142 is transferred\n",
      "n01983481 is transferred\n",
      "n02087046 is transferred\n",
      "n01820546 is transferred\n",
      "n04238763 is transferred\n",
      "n02093428 is transferred\n",
      "n02116738 is transferred\n",
      "n02104029 is transferred\n",
      "n04229816 is transferred\n",
      "n03837869 is transferred\n",
      "n07836838 is transferred\n",
      "n07715103 is transferred\n",
      "n04435653 is transferred\n",
      "n02231487 is transferred\n",
      "n01692333 is transferred\n",
      "n04111531 is transferred\n",
      "n02108089 is transferred\n",
      "n13040303 is transferred\n",
      "n01729322 is transferred\n",
      "n04026417 is transferred\n",
      "n03642806 is transferred\n",
      "n02974003 is transferred\n",
      "n03764736 is transferred\n",
      "n02113799 is transferred\n",
      "n02009229 is transferred\n",
      "n02123045 is transferred\n",
      "n02396427 is transferred\n",
      "n02086240 is transferred\n",
      "n01978455 is transferred\n",
      "n07714571 is transferred\n",
      "n04067472 is transferred\n",
      "n03787032 is transferred\n",
      "n03637318 is transferred\n",
      "n02100583 is transferred\n",
      "n03379051 is transferred\n",
      "n01558993 is transferred\n",
      "n01773797 is transferred\n",
      "n03530642 is transferred\n",
      "n02089867 is transferred\n",
      "n03903868 is transferred\n",
      "n02114855 is transferred\n",
      "n01749939 is transferred\n",
      "n04592741 is transferred\n",
      "n02090622 is transferred\n",
      "n03017168 is transferred\n",
      "n13037406 is transferred\n",
      "n03492542 is transferred\n",
      "n03947888 is transferred\n",
      "n02109047 is transferred\n",
      "n04589890 is transferred\n",
      "n03794056 is transferred\n",
      "n03777754 is transferred\n",
      "n03775546 is transferred\n",
      "n07831146 is transferred\n",
      "n02106550 is transferred\n",
      "n02788148 is transferred\n",
      "n07753275 is transferred\n",
      "n02085620 is transferred\n",
      "n02804414 is transferred\n",
      "n02105505 is transferred\n",
      "n04418357 is transferred\n",
      "n02877765 is transferred\n",
      "n02701002 is transferred\n",
      "n04429376 is transferred\n",
      "n03424325 is transferred\n",
      "n04493381 is transferred\n",
      "n03259280 is transferred\n",
      "n02089973 is transferred\n",
      "n04517823 is transferred\n",
      "n04127249 is transferred\n",
      "n04136333 is transferred\n",
      "n02869837 is transferred\n",
      "n04485082 is transferred\n",
      "n02091831 is transferred\n",
      "n04336792 is transferred\n",
      "n02859443 is transferred\n",
      "n02172182 is transferred\n",
      "n03085013 is transferred\n",
      "n03891251 is transferred\n",
      "n03785016 is transferred\n",
      "n02138441 is transferred\n",
      "n02488291 is transferred\n",
      "n02326432 is transferred\n",
      "n03032252 is transferred\n",
      "n03062245 is transferred\n",
      "n01855672 is transferred\n",
      "n03594734 is transferred\n",
      "n02086910 is transferred\n",
      "n03930630 is transferred\n",
      "n02483362 is transferred\n",
      "n03494278 is transferred\n",
      "n02113978 is transferred\n",
      "n02099849 is transferred\n",
      "n04099969 is transferred\n",
      "n03584829 is transferred\n",
      "n02119022 is transferred\n"
     ]
    }
   ],
   "source": [
    "generate_data(source_folder, target_folder, target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5acd0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "056c6b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pandas\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "from model import Model, Image_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be98f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f107d481",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_data, memory_data, test_data = utils.get_dataset('imagenet')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=24, pin_memory=True, drop_last=True)\n",
    "memory_loader = DataLoader(memory_data, batch_size=batch_size, shuffle=False, num_workers=24, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=24, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8a76c37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0227,  0.3138,  0.7419,  ...,  1.4098,  1.3584,  1.2728],\n",
       "          [ 0.0398,  0.4508,  0.8447,  ...,  1.3413,  1.3242,  1.2557],\n",
       "          [ 0.1597,  0.6392,  0.5707,  ...,  1.2899,  1.2728,  1.2385],\n",
       "          ...,\n",
       "          [-0.4911, -0.5596, -0.4911,  ..., -0.1143, -0.0116, -0.0629],\n",
       "          [-0.5253, -0.5767, -0.4739,  ..., -0.0629,  0.1083,  0.2111],\n",
       "          [-0.5253, -0.5596, -0.4568,  ...,  0.2967,  0.3994,  0.2624]],\n",
       " \n",
       "         [[ 0.1352,  0.4853,  0.9230,  ...,  1.4657,  1.4132,  1.3256],\n",
       "          [ 0.2052,  0.6429,  0.9580,  ...,  1.3957,  1.3782,  1.3081],\n",
       "          [ 0.3803,  0.6604,  0.4503,  ...,  1.3431,  1.3256,  1.2906],\n",
       "          ...,\n",
       "          [-0.5476, -0.6001, -0.5301,  ..., -0.1099, -0.0399, -0.1099],\n",
       "          [-0.6176, -0.6352, -0.4951,  ..., -0.0574,  0.1527,  0.2402],\n",
       "          [-0.6352, -0.6176, -0.4776,  ...,  0.2052,  0.3803,  0.3277]],\n",
       " \n",
       "         [[ 0.0431,  0.4614,  1.0191,  ...,  1.4722,  1.4200,  1.3328],\n",
       "          [ 0.1651,  0.5834,  0.9842,  ...,  1.4025,  1.3851,  1.3154],\n",
       "          [ 0.3219,  0.6879,  0.4962,  ...,  1.3502,  1.3328,  1.2980],\n",
       "          ...,\n",
       "          [-0.4275, -0.5321, -0.3753,  ...,  0.0605,  0.1128,  0.0431],\n",
       "          [-0.4973, -0.5670, -0.3578,  ...,  0.0605,  0.1651,  0.1999],\n",
       "          [-0.5147, -0.5495, -0.3578,  ...,  0.1999,  0.3916,  0.3393]]]),\n",
       " tensor([[[1.2728, 1.2728, 1.2728,  ..., 0.8104, 0.7933, 0.7933],\n",
       "          [1.2728, 1.2728, 1.2728,  ..., 0.8104, 0.7933, 0.7762],\n",
       "          [1.2557, 1.2557, 1.2557,  ..., 0.8104, 0.7762, 0.7591],\n",
       "          ...,\n",
       "          [0.6221, 0.6392, 0.6734,  ..., 1.9064, 1.9235, 1.9407],\n",
       "          [0.6049, 0.6221, 0.6392,  ..., 1.9064, 1.9064, 1.9064],\n",
       "          [0.5878, 0.6049, 0.6221,  ..., 1.9064, 1.8893, 1.8893]],\n",
       " \n",
       "         [[1.1506, 1.1506, 1.1506,  ..., 0.6604, 0.6954, 0.7129],\n",
       "          [1.1506, 1.1506, 1.1506,  ..., 0.6604, 0.6954, 0.6954],\n",
       "          [1.1331, 1.1331, 1.1331,  ..., 0.6779, 0.6779, 0.6779],\n",
       "          ...,\n",
       "          [0.6254, 0.6429, 0.6779,  ..., 2.0609, 2.0434, 2.0434],\n",
       "          [0.6078, 0.6254, 0.6604,  ..., 2.0609, 2.0434, 2.0434],\n",
       "          [0.6078, 0.6254, 0.6604,  ..., 2.0609, 2.0434, 2.0434]],\n",
       " \n",
       "         [[1.0888, 1.0888, 1.0888,  ..., 0.5659, 0.6182, 0.6531],\n",
       "          [1.0888, 1.0888, 1.0888,  ..., 0.5311, 0.6008, 0.6356],\n",
       "          [1.0714, 1.0714, 1.0714,  ..., 0.4962, 0.5659, 0.6182],\n",
       "          ...,\n",
       "          [0.5136, 0.5311, 0.5834,  ..., 2.1868, 2.2043, 2.2043],\n",
       "          [0.5311, 0.5485, 0.5659,  ..., 2.1868, 2.1868, 2.1868],\n",
       "          [0.5485, 0.5485, 0.5485,  ..., 2.1868, 2.1868, 2.1868]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535dae5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:main]",
   "language": "python",
   "name": "conda-env-main-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
